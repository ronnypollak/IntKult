% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{anyt/global//global/global}
  \entry{yang_cross-datasets_2022}{incollection}{}
    \name{author}{3}{}{%
      {{hash=ARS}{%
         family={Al-Riyami},
         familyi={A\bibinithyphendelim R\bibinitperiod},
         given={Said},
         giveni={S\bibinitperiod},
      }}%
      {{hash=LA}{%
         family={Lisitsa},
         familyi={L\bibinitperiod},
         given={Alexei},
         giveni={A\bibinitperiod},
      }}%
      {{hash=CF}{%
         family={Coenen},
         familyi={C\bibinitperiod},
         given={Frans},
         giveni={F\bibinitperiod},
      }}%
    }
    \name{editor}{4}{}{%
      {{hash=YXS}{%
         family={Yang},
         familyi={Y\bibinitperiod},
         given={Xin-She},
         giveni={X\bibinithyphendelim S\bibinitperiod},
      }}%
      {{hash=SS}{%
         family={Sherratt},
         familyi={S\bibinitperiod},
         given={Simon},
         giveni={S\bibinitperiod},
      }}%
      {{hash=DN}{%
         family={Dey},
         familyi={D\bibinitperiod},
         given={Nilanjan},
         giveni={N\bibinitperiod},
      }}%
      {{hash=JA}{%
         family={Joshi},
         familyi={J\bibinitperiod},
         given={Amit},
         giveni={A\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Springer Singapore}%
    }
    \strng{namehash}{ARSLACF1}
    \strng{fullhash}{ARSLACF1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelalpha}{ARLC22}
    \field{sortinit}{A}
    \field{sortinithash}{A}
    \field{abstract}{%
    The conventional way to evaluate the performance of machine learning models
  intrusion detection systems ({IDS}) is by using the same dataset to train and
  test. This method might lead to the bias from the computer network where the
  traﬃc is generated. Because of that, the applicability of the learned
  models might not be adequately evaluated. We argued in [1] that a better way
  is to use cross-datasets evaluation, where we use two diﬀerent datasets for
  training and testing. Both datasets should be generated from various
  networks. Using this method as it was shown in [1] may lead to a signiﬁcant
  drop in the performance of the learned model. This indicates that the models
  learn very little knowledge about the intrusion, which would be transferable
  from one setting to another. The reasons for such behaviour were not fully
  understood in [1]. In this paper, we investigate the problem and show that
  the main reason is the diﬀerent deﬁnitions of the same feature in both
  models. We propose the correction and further empirically investigate
  cross-datasets evaluation for various machine learning methods. Further, we
  explored cross-dataset evaluation in the multi-class classiﬁcation of
  attacks, and we show for the most models that learning traﬃc normality is
  more robust than learning intrusions.%
    }
    \field{booktitle}{Proceedings of Sixth International Congress on
  Information and Communication Technology}
    \verb{doi}
    \verb 10.1007/978-981-16-2102-4_73
    \endverb
    \field{isbn}{9789811621017 9789811621024}
    \field{note}{Series Title: Lecture Notes in Networks and Systems}
    \field{pages}{815\bibrangedash 828}
    \field{title}{Cross-Datasets Evaluation of Machine Learning Models for
  Intrusion Detection Systems}
    \verb{url}
    \verb https://link.springer.com/10.1007/978-981-16-2102-4_73
    \endverb
    \field{volume}{217}
    \field{langid}{english}
    \list{location}{1}{%
      {Singapore}%
    }
    \field{year}{2022}
    \field{urlday}{21}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry

  \entry{buolamwini_gender_2018}{inproceedings}{}
    \name{author}{2}{}{%
      {{hash=BJ}{%
         family={Buolamwini},
         familyi={B\bibinitperiod},
         given={Joy},
         giveni={J\bibinitperiod},
      }}%
      {{hash=GT}{%
         family={Gebru},
         familyi={G\bibinitperiod},
         given={Timnit},
         giveni={T\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {{PMLR}}%
    }
    \strng{namehash}{BJGT1}
    \strng{fullhash}{BJGT1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{labelalpha}{BG18}
    \field{sortinit}{B}
    \field{sortinithash}{B}
    \field{abstract}{%
    Recent studies demonstrate that machine learning algorithms can
  discriminate based on classes like race and gender. In this work, we present
  an approach to evaluate bias present in automated facial analysis algorithms
  and datasets with respect to phenotypic subgroups. Using the dermatologist
  approved Fitzpatrick Skin Type classification system, we characterize the
  gender and skin type distribution of two facial analysis benchmarks, {IJB}-A
  and Adience. We find that these datasets are overwhelmingly composed of
  lighter-skinned subjects (79.6\% for {IJB}-A and 86.2\% for Adience) and
  introduce a new facial analysis dataset which is balanced by gender and skin
  type. We evaluate 3 commercial gender classification systems using our
  dataset and show that darker-skinned females are the most misclassified group
  (with error rates of up to 34.7\%). The maximum error rate for
  lighter-skinned males is 0.8\%. The substantial disparities in the accuracy
  of classifying darker females, lighter females, darker males, and lighter
  males in gender classification systems require urgent attention if commercial
  companies are to build genuinely fair, transparent and accountable facial
  analysis algorithms.%
    }
    \field{booktitle}{Proceedings of the 1st Conference on Fairness,
  Accountability and Transparency}
    \field{eventtitle}{Conference on Fairness, Accountability and Transparency}
    \field{note}{{ISSN}: 2640-3498}
    \field{pages}{77\bibrangedash 91}
    \field{shorttitle}{Gender Shades}
    \field{title}{Gender Shades: Intersectional Accuracy Disparities in
  Commercial Gender Classification}
    \verb{url}
    \verb https://proceedings.mlr.press/v81/buolamwini18a.html
    \endverb
    \field{langid}{english}
    \field{day}{21}
    \field{month}{01}
    \field{year}{2018}
    \field{urlday}{20}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry

  \entry{bacchini_race_2019}{article}{}
    \name{author}{2}{}{%
      {{hash=BF}{%
         family={Bacchini},
         familyi={B\bibinitperiod},
         given={Fabio},
         giveni={F\bibinitperiod},
      }}%
      {{hash=LL}{%
         family={Lorusso},
         familyi={L\bibinitperiod},
         given={Ludovica},
         giveni={L\bibinitperiod},
      }}%
    }
    \strng{namehash}{BFLL1}
    \strng{fullhash}{BFLL1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{labelalpha}{BL19}
    \field{sortinit}{B}
    \field{sortinithash}{B}
    \field{abstract}{%
    Purpose This study aims to explore whether face recognition technology –
  as it is intensely used by state and local police departments and law
  enforcement agencies – is racism free or, on the contrary, is affected by
  racial biases and/or racist prejudices, thus reinforcing overall racial
  discrimination.Design/methodology/approach The study investigates the causal
  pathways through which face recognition technology may reinforce the racial
  disproportion in enforcement; it also inquires whether it further
  discriminates black people by making them experience more racial
  discrimination and self-identify more decisively as black – two conditions
  that are shown to be harmful in various respects.Findings This study shows
  that face recognition technology, as it is produced, implemented and used in
  Western societies, reinforces existing racial disparities in stop,
  investigation, arrest and incarceration rates because of racist prejudices
  and even contributes to strengthen the unhealthy effects of racism on
  historically disadvantaged racial groups, like black people.Practical
  implications The findings hope to make law enforcement agencies and software
  companies aware that they must take adequate action against the racially
  discriminative effects of the use of face recognition technology.Social
  implications This study highlights that no implementation of an allegedly
  racism-free biometric technology is safe from the risk of racially
  discriminating, simply because each implementation leans against our society,
  which is affected by racism in many persisting ways.Originality/value While
  the ethical survey of biometric technologies is traditionally framed in the
  discourse of universal rights, this study explores an issue that has not been
  deeply scrutinized so far, that is, how face recognition technology
  differently affects distinct racial groups and how it contributes to racial
  discrimination.%
    }
    \verb{doi}
    \verb 10.1108/JICES-05-2018-0050
    \endverb
    \field{issn}{1477-996X}
    \field{note}{Publisher: Emerald Publishing Limited}
    \field{number}{3}
    \field{pages}{321\bibrangedash 335}
    \field{shorttitle}{Race, again}
    \field{title}{Race, again: how face recognition technology reinforces
  racial discrimination}
    \verb{url}
    \verb https://doi.org/10.1108/JICES-05-2018-0050
    \endverb
    \field{volume}{17}
    \field{journaltitle}{Journal of Information, Communication and Ethics in
  Society}
    \field{day}{01}
    \field{month}{01}
    \field{year}{2019}
    \field{urlday}{14}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry

  \entry{chen_cdevalsumm_2020}{inproceedings}{}
    \name{author}{7}{}{%
      {{hash=CY}{%
         family={Chen},
         familyi={C\bibinitperiod},
         given={Yiran},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=LP}{%
         family={Liu},
         familyi={L\bibinitperiod},
         given={Pengfei},
         giveni={P\bibinitperiod},
      }}%
      {{hash=ZM}{%
         family={Zhong},
         familyi={Z\bibinitperiod},
         given={Ming},
         giveni={M\bibinitperiod},
      }}%
      {{hash=DZY}{%
         family={Dou},
         familyi={D\bibinitperiod},
         given={Zi-Yi},
         giveni={Z\bibinithyphendelim Y\bibinitperiod},
      }}%
      {{hash=WD}{%
         family={Wang},
         familyi={W\bibinitperiod},
         given={Danqing},
         giveni={D\bibinitperiod},
      }}%
      {{hash=QX}{%
         family={Qiu},
         familyi={Q\bibinitperiod},
         given={Xipeng},
         giveni={X\bibinitperiod},
      }}%
      {{hash=HX}{%
         family={Huang},
         familyi={H\bibinitperiod},
         given={Xuanjing},
         giveni={X\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Association for Computational Linguistics}%
    }
    \strng{namehash}{CY+1}
    \strng{fullhash}{CYLPZMDZYWDQXHX1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{labelalpha}{Che+20}
    \field{sortinit}{C}
    \field{sortinithash}{C}
    \field{abstract}{%
    Neural network-based models augmented with unsupervised pre-trained
  knowledge have achieved impressive performance on text summarization.
  However, most existing evaluation methods are limited to an in-domain
  setting, where summarizers are trained and evaluated on the same dataset. We
  argue that this approach can narrow our understanding of the generalization
  ability for different summarization systems. In this paper, we perform an
  in-depth analysis of characteristics of different datasets and investigate
  the performance of different summarization models under a cross-dataset
  setting, in which a summarizer trained on one corpus will be evaluated on a
  range of out-of-domain corpora. A comprehensive study of 11 representative
  summarization systems on 5 datasets from different domains reveals the effect
  of model architectures and generation ways (i.e. abstractive and extractive)
  on model generalization ability. Further, experimental results shed light on
  the limitations of existing summarizers. Brief introduction and supplementary
  code can be found in https://github.com/zide05/{CDEvalSumm}.%
    }
    \field{booktitle}{Findings of the Association for Computational
  Linguistics: {EMNLP} 2020}
    \verb{doi}
    \verb 10.18653/v1/2020.findings-emnlp.329
    \endverb
    \field{eventtitle}{Findings 2020}
    \field{pages}{3679\bibrangedash 3691}
    \field{shorttitle}{{CDEvalSumm}}
    \field{title}{{CDEvalSumm}: An Empirical Study of Cross-Dataset Evaluation
  for Neural Summarization Systems}
    \verb{url}
    \verb https://aclanthology.org/2020.findings-emnlp.329
    \endverb
    \list{location}{1}{%
      {Online}%
    }
    \field{month}{11}
    \field{year}{2020}
    \field{urlday}{21}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry

  \entry{khan_guide_2018}{book}{}
    \name{author}{4}{}{%
      {{hash=KS}{%
         family={Khan},
         familyi={K\bibinitperiod},
         given={Salman},
         giveni={S\bibinitperiod},
      }}%
      {{hash=RH}{%
         family={Rahmani},
         familyi={R\bibinitperiod},
         given={Hossein},
         giveni={H\bibinitperiod},
      }}%
      {{hash=SSAA}{%
         family={Shah},
         familyi={S\bibinitperiod},
         given={Syed Afaq\bibnamedelima Ali},
         giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod\bibinitdelim
  A\bibinitperiod},
      }}%
      {{hash=BM}{%
         family={Bennamoun},
         familyi={B\bibinitperiod},
         given={Mohammed},
         giveni={M\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Springer International Publishing}%
    }
    \strng{namehash}{KS+1}
    \strng{fullhash}{KSRHSSAABM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelalpha}{Kha+18}
    \field{sortinit}{K}
    \field{sortinithash}{K}
    \verb{doi}
    \verb 10.1007/978-3-031-01821-3
    \endverb
    \field{isbn}{978-3-031-00693-7 978-3-031-01821-3}
    \field{series}{Synthesis Lectures on Computer Vision}
    \field{title}{A Guide to Convolutional Neural Networks for Computer Vision}
    \verb{url}
    \verb https://link.springer.com/10.1007/978-3-031-01821-3
    \endverb
    \field{langid}{english}
    \list{location}{1}{%
      {Cham}%
    }
    \field{year}{2018}
    \field{urlday}{20}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry

  \entry{usa}{report}{}
    \name{author}{3}{}{%
      {{hash=MC}{%
         family={Muñoz},
         familyi={M\bibinitperiod},
         given={Cecilia},
         giveni={C\bibinitperiod},
      }}%
      {{hash=SM}{%
         family={Smith},
         familyi={S\bibinitperiod},
         given={Megan},
         giveni={M\bibinitperiod},
      }}%
      {{hash=PD}{%
         family={Patil},
         familyi={P\bibinitperiod},
         given={DJ},
         giveni={D\bibinitperiod},
      }}%
    }
    \strng{namehash}{MCSMPD1}
    \strng{fullhash}{MCSMPD1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelalpha}{MSP16}
    \field{sortinit}{M}
    \field{sortinithash}{M}
    \field{title}{Big Data: A Report on Algorithmic Systems, Opportunity, and
  Civil Rights}
    \list{institution}{1}{%
      {Executive Office of the President}%
    }
    \field{type}{•}
    \field{year}{2016}
    \warn{\item Invalid format of field 'month'}
  \endentry

  \entry{nanni2022feature}{article}{}
    \name{author}{4}{}{%
      {{hash=NL}{%
         family={Nanni},
         familyi={N\bibinitperiod},
         given={Loris},
         giveni={L\bibinitperiod},
      }}%
      {{hash=PM}{%
         family={Paci},
         familyi={P\bibinitperiod},
         given={Michelangelo},
         giveni={M\bibinitperiod},
      }}%
      {{hash=BS}{%
         family={Brahnam},
         familyi={B\bibinitperiod},
         given={Sheryl},
         giveni={S\bibinitperiod},
      }}%
      {{hash=LA}{%
         family={Lumini},
         familyi={L\bibinitperiod},
         given={Alessandra},
         giveni={A\bibinitperiod},
      }}%
    }
    \strng{namehash}{NL+1}
    \strng{fullhash}{NLPMBSLA1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelalpha}{Nan+}
    \field{sortinit}{N}
    \field{sortinithash}{N}
    \field{title}{Feature transforms for image data augmentation}
    \field{journaltitle}{arXiv preprint arXiv:2201.09700}
  \endentry

  \entry{fairness}{article}{}
    \name{author}{2}{}{%
      {{hash=PD}{%
         family={Pessach},
         familyi={P\bibinitperiod},
         given={Dana},
         giveni={D\bibinitperiod},
      }}%
      {{hash=SE}{%
         family={Shmueli},
         familyi={S\bibinitperiod},
         given={Erez},
         giveni={E\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Association for Computing Machinery}%
    }
    \strng{namehash}{PDSE1}
    \strng{fullhash}{PDSE1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelalpha}{PS22}
    \field{sortinit}{P}
    \field{sortinithash}{P}
    \field{issn}{0360-0300}
    \field{number}{3}
    \field{title}{A Review on Fairness in Machine Learning}
    \verb{url}
    \verb https://doi.org/10.1145/3494672
    \endverb
    \field{volume}{55}
    \list{location}{1}{%
      {New York, NY, USA}%
    }
    \field{year}{2022}
  \endentry

  \entry{singh_face_2020}{online}{}
    \name{author}{1}{}{%
      {{hash=SM}{%
         family={Singh},
         familyi={S\bibinitperiod},
         given={Manmeet},
         giveni={M\bibinitperiod},
      }}%
    }
    \strng{namehash}{SM1}
    \strng{fullhash}{SM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelalpha}{Sin20}
    \field{sortinit}{S}
    \field{sortinithash}{S}
    \field{abstract}{%
    This article is a brief outline on various state-of-art techniques used for
  face data augmentation.%
    }
    \field{titleaddon}{Medium}
    \field{title}{Face Data Augmentation Techniques}
    \verb{url}
    \verb https://manmeet3.medium.com/face-data-augmentation-techniques-ace9e8d
    \verb db030
    \endverb
    \field{langid}{english}
    \field{day}{25}
    \field{month}{05}
    \field{year}{2020}
    \field{urlday}{20}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry
\enddatalist
\endinput
