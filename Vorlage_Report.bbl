% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{anyt/global//global/global}
  \entry{buolamwini_gender_2018}{inproceedings}{}
    \name{author}{2}{}{%
      {{hash=BJ}{%
         family={Buolamwini},
         familyi={B\bibinitperiod},
         given={Joy},
         giveni={J\bibinitperiod},
      }}%
      {{hash=GT}{%
         family={Gebru},
         familyi={G\bibinitperiod},
         given={Timnit},
         giveni={T\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {{PMLR}}%
    }
    \strng{namehash}{BJGT1}
    \strng{fullhash}{BJGT1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{labelalpha}{BG18}
    \field{sortinit}{B}
    \field{sortinithash}{B}
    \field{abstract}{%
    Recent studies demonstrate that machine learning algorithms can
  discriminate based on classes like race and gender. In this work, we present
  an approach to evaluate bias present in automated facial analysis algorithms
  and datasets with respect to phenotypic subgroups. Using the dermatologist
  approved Fitzpatrick Skin Type classification system, we characterize the
  gender and skin type distribution of two facial analysis benchmarks, {IJB}-A
  and Adience. We find that these datasets are overwhelmingly composed of
  lighter-skinned subjects (79.6\% for {IJB}-A and 86.2\% for Adience) and
  introduce a new facial analysis dataset which is balanced by gender and skin
  type. We evaluate 3 commercial gender classification systems using our
  dataset and show that darker-skinned females are the most misclassified group
  (with error rates of up to 34.7\%). The maximum error rate for
  lighter-skinned males is 0.8\%. The substantial disparities in the accuracy
  of classifying darker females, lighter females, darker males, and lighter
  males in gender classification systems require urgent attention if commercial
  companies are to build genuinely fair, transparent and accountable facial
  analysis algorithms.%
    }
    \field{booktitle}{Proceedings of the 1st Conference on Fairness,
  Accountability and Transparency}
    \field{eventtitle}{Conference on Fairness, Accountability and Transparency}
    \field{note}{{ISSN}: 2640-3498}
    \field{pages}{77\bibrangedash 91}
    \field{shorttitle}{Gender Shades}
    \field{title}{Gender Shades: Intersectional Accuracy Disparities in
  Commercial Gender Classification}
    \verb{url}
    \verb https://proceedings.mlr.press/v81/buolamwini18a.html
    \endverb
    \field{langid}{english}
    \field{day}{21}
    \field{month}{01}
    \field{year}{2018}
    \field{urlday}{20}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry

  \entry{bacchini_race_2019}{article}{}
    \name{author}{2}{}{%
      {{hash=BF}{%
         family={Bacchini},
         familyi={B\bibinitperiod},
         given={Fabio},
         giveni={F\bibinitperiod},
      }}%
      {{hash=LL}{%
         family={Lorusso},
         familyi={L\bibinitperiod},
         given={Ludovica},
         giveni={L\bibinitperiod},
      }}%
    }
    \strng{namehash}{BFLL1}
    \strng{fullhash}{BFLL1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{labelalpha}{BL19}
    \field{sortinit}{B}
    \field{sortinithash}{B}
    \field{abstract}{%
    Purpose This study aims to explore whether face recognition technology –
  as it is intensely used by state and local police departments and law
  enforcement agencies – is racism free or, on the contrary, is affected by
  racial biases and/or racist prejudices, thus reinforcing overall racial
  discrimination.Design/methodology/approach The study investigates the causal
  pathways through which face recognition technology may reinforce the racial
  disproportion in enforcement; it also inquires whether it further
  discriminates black people by making them experience more racial
  discrimination and self-identify more decisively as black – two conditions
  that are shown to be harmful in various respects.Findings This study shows
  that face recognition technology, as it is produced, implemented and used in
  Western societies, reinforces existing racial disparities in stop,
  investigation, arrest and incarceration rates because of racist prejudices
  and even contributes to strengthen the unhealthy effects of racism on
  historically disadvantaged racial groups, like black people.Practical
  implications The findings hope to make law enforcement agencies and software
  companies aware that they must take adequate action against the racially
  discriminative effects of the use of face recognition technology.Social
  implications This study highlights that no implementation of an allegedly
  racism-free biometric technology is safe from the risk of racially
  discriminating, simply because each implementation leans against our society,
  which is affected by racism in many persisting ways.Originality/value While
  the ethical survey of biometric technologies is traditionally framed in the
  discourse of universal rights, this study explores an issue that has not been
  deeply scrutinized so far, that is, how face recognition technology
  differently affects distinct racial groups and how it contributes to racial
  discrimination.%
    }
    \verb{doi}
    \verb 10.1108/JICES-05-2018-0050
    \endverb
    \field{issn}{1477-996X}
    \field{note}{Publisher: Emerald Publishing Limited}
    \field{number}{3}
    \field{pages}{321\bibrangedash 335}
    \field{shorttitle}{Race, again}
    \field{title}{Race, again: how face recognition technology reinforces
  racial discrimination}
    \verb{url}
    \verb https://doi.org/10.1108/JICES-05-2018-0050
    \endverb
    \field{volume}{17}
    \field{journaltitle}{Journal of Information, Communication and Ethics in
  Society}
    \field{day}{01}
    \field{month}{01}
    \field{year}{2019}
    \field{urlday}{14}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry

  \entry{usa}{report}{}
    \name{author}{1}{}{%
      {{hash=CMDPMS}{%
         family={Cecilia\bibnamedelima Muñoz},
         familyi={C\bibinitperiod\bibinitdelim M\bibinitperiod},
         suffix={Megan\bibnamedelima Smith},
         suffixi={M\bibinitperiod\bibinitdelim S\bibinitperiod},
         given={DJ\bibnamedelima Patil},
         giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod},
      }}%
    }
    \strng{namehash}{CMMSDP1}
    \strng{fullhash}{CMMSDP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelalpha}{CM16}
    \field{sortinit}{C}
    \field{sortinithash}{C}
    \field{title}{Big Data: A Report on Algorithmic Systems, Opportunity, and
  Civil Rights}
    \list{institution}{1}{%
      {Executive Office of the President}%
    }
    \field{type}{•}
    \field{year}{2016}
    \warn{\item Invalid format of field 'month'}
  \endentry

  \entry{khan_guide_2018}{book}{}
    \name{author}{4}{}{%
      {{hash=KS}{%
         family={Khan},
         familyi={K\bibinitperiod},
         given={Salman},
         giveni={S\bibinitperiod},
      }}%
      {{hash=RH}{%
         family={Rahmani},
         familyi={R\bibinitperiod},
         given={Hossein},
         giveni={H\bibinitperiod},
      }}%
      {{hash=SSAA}{%
         family={Shah},
         familyi={S\bibinitperiod},
         given={Syed Afaq\bibnamedelima Ali},
         giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod\bibinitdelim
  A\bibinitperiod},
      }}%
      {{hash=BM}{%
         family={Bennamoun},
         familyi={B\bibinitperiod},
         given={Mohammed},
         giveni={M\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Springer International Publishing}%
    }
    \strng{namehash}{KS+1}
    \strng{fullhash}{KSRHSSAABM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelalpha}{Kha+18}
    \field{sortinit}{K}
    \field{sortinithash}{K}
    \verb{doi}
    \verb 10.1007/978-3-031-01821-3
    \endverb
    \field{isbn}{978-3-031-00693-7 978-3-031-01821-3}
    \field{series}{Synthesis Lectures on Computer Vision}
    \field{title}{A Guide to Convolutional Neural Networks for Computer Vision}
    \verb{url}
    \verb https://link.springer.com/10.1007/978-3-031-01821-3
    \endverb
    \field{langid}{english}
    \list{location}{1}{%
      {Cham}%
    }
    \field{year}{2018}
    \field{urlday}{20}
    \field{urlmonth}{01}
    \field{urlyear}{2023}
  \endentry
\enddatalist
\endinput
